# 视频项目
## Rock去重
![image.png](https://image-yupan.cixingji.cloud/study/20260112191009344.png)
### 整体的流程
#### 原本：
是给每个用户搞一个Redis布隆过滤器
#### 现在：
1. **查询流：（过滤掉“看过的”）**
    1. 第一层：Redis拦截，先去Redis的Zset里查用户最近看的50条。
           有就不推荐，没有去下一层。
    2. 第二层：磁盘KV ROcksDB中读取这个用户的布隆过滤器。
           命中虽然误判但是不推荐，没命中绝对没看过推荐。
2. **同步流：（更新“看过的”）**
    1. 实时录入：用户看完一个视频，把这个视频ID丢进Redis 的缓存中，同时把这个用户ID放进当前小时的 活跃用户桶。
    2. 时间片触发批处理：
        1. 时间转动：到 15:00 时，系统开始处理 14:00 那个“已经封盘”的用户桶。
        2. 批量合并：从桶里拿出一个 User ID。从 RocksDB 取出旧的 BF，从 Redis 取出这 1 小时存的视频列表。把列表里的 ID 全部 add 到 BF 里。把更新后的 BF 一次性写回 RocksDB。
        3. 清理临时：删除Redis里这个用户列表和视频列表临时的
3. **滚动淘汰：（清除超远的数据的）**
    1. 为了防止 BF 越来越满导致误判率飙升，系统按月切分：
    2. 当前月：可读可写
    3. 历史月：只读
    4. 自动化：到新月份，很远的老月份的BF因为设置了TTL会被清除在RocksDB中。

### 技术选型的原因

- **冷数据从存具体ID→布隆过滤器：**
    原因：空间占用缩减，缺点是有小的误判的情况，但是对于推荐系统来说无伤大雅
- **内存→内存+硬盘**
    原因：冷热分离，内存太贵，大部分数据转到了硬盘上。
- **实时写→时间轮转批处理**
    原因：在于把千万级的实时的随机写，变成低频的批处理，减小磁盘压力。

#### 时间片机制
![image.png](https://image-yupan.cixingji.cloud/study/20260112184940743.png)

1. 24小时的时间环，设计一个定时任务Schedule，每小时执行一次，但是是执行前一个小时的数据，**延迟处理**。好处是处理之前的数据**不需要担心增量干扰**。
2. 这个环形的结构天然的就有**失败补偿**的效果。第一天任务如果失败了，第二天依然会处理前一天的补偿

#### 数据淘汰
![image.png](https://image-yupan.cixingji.cloud/study/20260112192435702.png)

分片存储，按月份
**滑动窗口**：去重的时候只检查最近三个月的BF就行
过期清理如上面说的

### 怎么切换的架构

**待写！**
![image.png](https://image-yupan.cixingji.cloud/study/20260112194606748.png)

更进一步：从旧 ZSet 方案一步步切到新架构

现实里很少有“停机切换”的机会，如何从原来的 Redis ZSet 精确存储平滑迁到「布隆过滤器 + 磁盘」架构，是另一个工程重点。

一个相对稳妥的策略是：延迟迁移 + 双读兜底。

上线初期，对于未迁移的用户，去重时同时读取新旧两份数据。在后台，通过定时任务，将被触发的用户数据异步地、批量地迁移到新的布隆过滤器结构中，整个过程对用户无感。实际迁移时，一般只会针对“最近 N 天有活跃”的用户做迁移，历史沉默用户按需懒迁或者不迁，进一步节省资源。

# AI面试项目

## @Traditional自调用失效

### 问题描述

在写知识库的上传逻辑的时候，Cursor帮我写了一个上传之后继续处理的流程，直接在同一个Service写了两个带事务的方法，然后在方法内部`this`调用了另一个方法。
``` java
@Service  
publicclass KnowledgeBaseUploadService {  
    @Transactional  
    public void uploadAndProcess(File file) {  
        saveFile(file);  
  
        // 自调用：绕过代理对象，导致 processInNewTx() 上的事务配置不生效  
        this.processInNewTx(file);  
    }  
  
    @Transactional(propagation = [Propagation.REQUIRES_NEW)](http://propagation.requires_new\)/)  
    public void processInNewTx(File file) {  
        // 期望在新事务运行（REQUIRES_NEW），但自调用会导致该注解不生效  
        // 结果：不会开启“新事务”，往往会在当前调用上下文（通常是外层事务）里执行  
    }  
}
```

### 原因

**底层原理**：**Spring AOP 动态代理**。

- Spring 的事务是通过代理对象（Proxy）实现的。当外部调用 `bean.method()` 时，实际上先进入代理对象开启事务，再调用目标对象。
    
- 而在类内部使用 `this.method()` 调用时，是**直接调用目标对象**，绕过了代理对象，导致拦截器无法生效。。

### 解决方案

把需要新事务的方法拆到另一个 Bean 上，通过注入后调用（确保经过代理）。

``` java
@Service  
@RequiredArgsConstructor  
publicclass KnowledgeBaseUploadService {  
  
    privatefinal KnowledgeBaseProcessService processService;  
  
    @Transactional  
    public void uploadAndProcess(File file) {  
        saveFile(file);  
        [processService.processInNewTx(file);](http://processservice.processinnewtx\(file\);/)  // 通过代理调用，事务增强生效  
    }  
}  
  
@Service  
publicclass KnowledgeBaseProcessService {  
  
    @Transactional(propagation = [Propagation.REQUIRES_NEW)](http://propagation.requires_new\)/)  
    public void processInNewTx(File file) {  
        // 现在可以保证以新事务边界执行  
    }  
}
```

## AI响应空指针

### 问题描述

面试评估功能在压力测试时，偶尔会报 `NullPointerException`，导致整个面试流程中断。

### 原因

LLM 的输出具有随机性。即使在提示里要求“必须返回 JSON”，也可能出现：

- 字段删除或为`null`
    
- 结构变化（字段名拼错）
    
- 类型不一致（数字变字符串）
    
- token 截断/中断导致 JSON 不完整

Cursor 写的解析代码太“简单”，直接相信了 AI 的输出。

### 解决方案

``` java
List evaluations = dto.questionEvaluations();

if (evaluations == null || evaluations.isEmpty()) {
    log.error("AI 响应异常：面试评估列表缺失或为空，sessionId={}", sessionId);
    
    // 兜底策略示例：直接降级为"无评估"，保证流程继续
    evaluations = Collections.emptyList();
    // 也可以 return + 返回默认评估结果，看你的业务需要
}

// 只处理与问题数量对齐的部分，避免越界
int n = Math.min(evaluations.size(), questions.size());
for (int i = 0; i < n; i++) {
    QuestionEvaluationDTO ev = evaluations.get(i);
    // 对 ev 内部字段也做必要校验（例如 ev.getScore() 为空就给默认值）
}
``` 

## 删除后依然报错

### 问题描述

后台日志频繁出现 `简历不存在: ID=35` 的 Error。

### 原因
   打断点检查发现，这是由于用户删除了简历，但分析任务还在跑。
   
这是导致数据不一致的典型问题：

1. 用户上传简历 → 发送分析任务到 Redis Stream
    
2. 分析失败 → 消息进入 pending/等待重试
    
3. 用户删除简历 → 数据库记录已删除
    
4. 消费者重试处理 → 找不到简历 → 报错

### 解决方案

把“生命周期校验”放在异步任务处理的最前面，并区分：

- **不可恢复错误**（实体不存在、参数非法）→ 记录后 ACK/丢弃
- **可恢复错误**（临时网络故障、依赖服务超时）→ 不 ACK，让其重试或进入重试队列

``` java
private void processMessage(StreamMessageId messageId, Map<String, String> data) {
    Long resumeId = Long.parseLong(data.get("resumeId"));

    var resumeOpt = resumeRepository.findById(resumeId);
    if (resumeOpt.isEmpty()) {
        // 不可恢复：实体已被用户删除（或数据已不存在）
        log.warn("检测到实体已被删除，跳过异步任务: resumeId={}", resumeId);
        ackMessage(messageId); // 必须 ACK，否则会反复重试造成噪音与堆积
        return;
    }

    try {
        Resume resume = resumeOpt.get();
        // 继续业务逻辑...
        ackMessage(messageId);
    } catch (TransientDependencyException e) {
        // 可恢复错误：不 ACK，让其重试（或转入重试/死信机制）
        log.warn("依赖异常，等待重试: resumeId={}, msgId={}", resumeId, messageId, e);
        throw e;
    } catch (Exception e) {
        // 根据你的策略决定是否 ACK/重试/转死信
        log.error("处理失败: resumeId={}, msgId={}", resumeId, messageId, e);
        throw e;
    }
}
```

## Stream队列堆积

### 问题描述

Redis 中有一个 Stream 积累了 100+ 条消息，且持续增长。

### 原因

一个常见的误区：`XACK` 只是确认消息已被消费，不会删除 Stream 里的消息条目。

- `XADD`：写入消息到 Stream
    
- `XREADGROUP`：消费者组读取消息
    
- `XACK`：确认消费（把消息从消费者组的 **PEL** / Pending Entries List “待处理列表”里移除）
    
- `XDEL`：从 Stream 中删除指定消息条目
    
- `XTRIM` / `MAXLEN`：裁剪 Stream（限制 Stream 长度，删除较旧的条目）
    

如果你既没有 `XDEL`，也没有 `XTRIM/MAXLEN`，那么 **Stream 里的历史消息会持续累积**，占用内存/磁盘。

### 解决方案

发送消息时添加 **MAXLEN 限制**，自动裁剪旧消息：

``` java
// 修复前
stream.add(StreamAddArgs.entries(message));

// 修复后（自动裁剪超过 1000 条的旧消息）
stream.add(StreamAddArgs.entries(message)
    .trimNonStrict().maxLen(1000));
```
