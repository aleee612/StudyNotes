## RAG
### RAG整体的顺序

### 怎么减少幻觉

1. **约束上下文：** 在 Prompt 中明确要求模型“仅根据提供的检索信息回答，若无信息则提示无法推荐”。
2. **RAG 兜底：** 结合 Redis 语义检索召回 Top-K 商品，将真实 ID、价格、库存作为 Context 输入，确保信息真实性。 
3. **引用来源：** 要求模型输出时带上引用标识，便于溯源验证。

### TOP-K

多次测试得到K多少，过小会导致信息缺失，过大则会引入噪音并浪费 Token。

### 数据清洗是什么

把数据转换成纯净的文本：
    删除无意义的符号，统一格式，去重
### 文档切分Chunking

按照固定大小切分，然后重合一部分，让句子不在中间断开

## AGent

### FunctionTool怎么判断调用

- **大模型如何决策：** 模型本身并不会直接运行代码。在发起请求时，后端会把工具的 **定义（JSON Schema，包含名称、描述、参数类型）** 发送给模型。模型根据用户的意图进行语义匹配，如果觉得需要用到工具，它会返回一个特殊的 `finish_reason: tool_calls`，并在响应中包含具体的**函数名**和**参数值**。
    
- **后端如何执行（Java）：** 在 Spring AI 中，你可以将工具定义为 `@Bean`。
    
    1. **映射：** 后端接收到模型的 JSON 指令后，通过反射机制或 Spring 的容器管理找到对应的 Bean。
        
    2. **执行：** 解析模型给出的参数，调用本地 Java 方法（如查询数据库或调用第三方 API）。
        
    3. **反馈：** 将方法的执行结果包装成一个新的 `ToolMessage` 发送回大模型。大模型拿到结果后，再组织成自然语言回答用户。

### ChatMemory机制

- 历史消息存储：
    
    在后端通常使用 Redis 存储。Key 为 SessionId，Value 是一个有序列表（List），存储了 UserMessage、AssistantMessage 和 ToolMessage。
    
- **Token 超限解决策略：**
    
    - **滑动窗口（Sliding Window）：** 只保留最近的 $N$ 轮对话。这是最简单、最常用的工程做法。
        
    - **对话摘要（Summary）：** 当对话达到一定长度时，调用一个更便宜的模型（如 GPT-4o-mini）将之前的对话总结成一段简短的 Context，替换掉老的消息。
        
    - **消息裁剪（Pruning）：** 优先删除中间过程产生的冗长 `ToolMessage`（工具执行结果），只保留核心的对话逻辑。
